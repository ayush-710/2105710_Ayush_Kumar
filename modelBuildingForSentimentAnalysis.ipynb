{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUDxTEmbU+ATT0BrqV4tQq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayush-710/Paradox/blob/main/modelBuildingForSentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining,Training and Testing The Model and Generating Classification Reports"
      ],
      "metadata": {
        "id": "X_jdxJrIL8xf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivW4XQje4grU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea366ccb-3d59-4230-8818-a542d72410f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "With Data Pre-Processing:\n",
            "Naive_Bayes accuracy_score = 86.75%\n",
            "Logistic_Regression accuracy_score = 89.43%\n",
            "Linear_SVC accuracy_score = 89.55%\n",
            "Stochastic_Gradient_Classifier accuracy_score = 89.54%\n",
            "With Data Pre-Processing and TF-IDF:\n",
            "Naive_Bayes accuracy_score = 86.75%\n",
            "Naive_Bayes classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.86      0.88      0.87      7499\n",
            "    Negative       0.87      0.86      0.87      7501\n",
            "\n",
            "    accuracy                           0.87     15000\n",
            "   macro avg       0.87      0.87      0.87     15000\n",
            "weighted avg       0.87      0.87      0.87     15000\n",
            "\n",
            "Logistic_Regression accuracy_score = 89.43%\n",
            "Logistic_Regression classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.91      0.88      0.89      7499\n",
            "    Negative       0.88      0.91      0.90      7501\n",
            "\n",
            "    accuracy                           0.89     15000\n",
            "   macro avg       0.89      0.89      0.89     15000\n",
            "weighted avg       0.89      0.89      0.89     15000\n",
            "\n",
            "Linear_SVC accuracy_score = 89.55%\n",
            "Linear_SVC classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.90      0.89      0.89      7499\n",
            "    Negative       0.89      0.90      0.90      7501\n",
            "\n",
            "    accuracy                           0.90     15000\n",
            "   macro avg       0.90      0.90      0.90     15000\n",
            "weighted avg       0.90      0.90      0.90     15000\n",
            "\n",
            "Stochastic_Gradient_Classifier accuracy_score = 89.51%\n",
            "Stochastic_Gradient_Classifier classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.91      0.88      0.89      7499\n",
            "    Negative       0.88      0.91      0.90      7501\n",
            "\n",
            "    accuracy                           0.90     15000\n",
            "   macro avg       0.90      0.90      0.90     15000\n",
            "weighted avg       0.90      0.90      0.90     15000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/MinorProjectDatasets/IMDB_Dataset_Cleaned.csv')\n",
        "\n",
        "# Drop rows with missing values\n",
        "df1 = df1.dropna(subset=['cleaned_text'])\n",
        "df1 = df1.dropna(subset=['sentiment'])\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(df1['cleaned_text'], df1['sentiment'], test_size=0.30, random_state=2)\n",
        "\n",
        "# Convert sentiments to 1 and 0\n",
        "y_train = (y_train.replace({'positive': 1, 'negative': 0})).values\n",
        "y_test = (y_test.replace({'positive': 1, 'negative': 0})).values\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(strip_accents=None,\n",
        "                         lowercase=True,\n",
        "                         preprocessor=None,  # applied preprocessor in Data Cleaning\n",
        "                         tokenizer=None,\n",
        "                         use_idf=True,\n",
        "                         norm='l2',\n",
        "                         smooth_idf=True)\n",
        "\n",
        "\n",
        "# Transform text data\n",
        "x_train_tfidf = tfidf.fit_transform(x_train)\n",
        "x_test_tfidf = tfidf.transform(x_test)\n",
        "# Model training and evaluation\n",
        "classifiers = {\n",
        "    \"Naive_Bayes\": MultinomialNB(),\n",
        "    \"Logistic_Regression\": LogisticRegression(),\n",
        "    # \"KNN\": KNeighborsClassifier(),\n",
        "    \"Linear_SVC\": LinearSVC(),\n",
        "    \"Stochastic_Gradient_Classifier\": SGDClassifier(),\n",
        "    # \"Random_Forest\": RandomForestClassifier()\n",
        "}\n",
        "\n",
        "print(\"With Data Pre-Processing:\")\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_train_tfidf, y_train)\n",
        "    accuracy = metrics.accuracy_score(clf.predict(x_test_tfidf), y_test)\n",
        "    print(f\"{name} accuracy_score = {accuracy * 100:.2f}%\")\n",
        "\n",
        "print(\"With Data Pre-Processing and TF-IDF:\")\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_train_tfidf, y_train)\n",
        "    y_pred = clf.predict(x_test_tfidf)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} accuracy_score = {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Classification report (ensure consistent target names)\n",
        "    report = classification_report(y_test, y_pred, target_names=['Positive', 'Negative'])\n",
        "    print(f\"{name} classification report:\\n{report}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performing Grid Search for hyperparameter tuning and evaluating the model"
      ],
      "metadata": {
        "id": "E8mKNEQyKQFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.base import clone  # Import clone function\n",
        "\n",
        "\n",
        "def grid_search_evaluate(model_name, model_class, param_grid):\n",
        "    \"\"\"\n",
        "    Performs Grid Search for hyperparameter tuning and evaluates the model.\n",
        "\n",
        "    Args:\n",
        "        model_name: Name of the model being evaluated.\n",
        "        model_class: The model class (e.g., MultinomialNB).\n",
        "        param_grid: Dictionary containing hyperparameter names and their values to explore.\n",
        "\n",
        "    Returns:\n",
        "        None (prints results)\n",
        "    \"\"\"\n",
        "    # Perform Grid Search\n",
        "    grid_search = GridSearchCV(model_class(), param_grid, cv=5, scoring='accuracy')\n",
        "    grid_search.fit(x_train_tfidf, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "    best_accuracy = grid_search.best_score_\n",
        "\n",
        "    # Evaluate and print results\n",
        "    y_pred = best_model.predict(x_test_tfidf)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{model_name} (Grid Search):\")\n",
        "    print(f\"Best Accuracy: {best_accuracy:.2f}\")\n",
        "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "    print(f\"{model_name} classification report:\\n{classification_report(y_test, y_pred, target_names=['Positive', 'Negative'])}\")\n",
        "    print(\"-\" * 80)  # Separator for clarity\n",
        "\n",
        "# Define hyperparameter grids (adjust values and parameters as needed)\n",
        "multinomialnb_grid = {'alpha': [0.01, 0.1, 1]}\n",
        "logistic_regression_grid = {'C': [0.01, 0.1, 1], 'penalty': ['l1', 'l2']}\n",
        "# knn_grid = {'n_neighbors': range(1, 10), 'algorithm': ['auto', 'ball_tree', 'kd_tree']}\n",
        "linear_svc_grid = {'C': [0.01, 0.1, 1]}\n",
        "sgdc_grid = {'alpha': [0.0001, 0.001, 0.01], 'loss': ['hinge', 'log']}\n",
        "# random_forest_grid = {'n_estimators': [100, 200, 300], 'max_depth': [5, 10, 15]}\n",
        "\n",
        "# Evaluate\n",
        "models = [\n",
        "    ('MultinomialNB', MultinomialNB),\n",
        "    ('Logistic_Regression', LogisticRegression),\n",
        "    # ('KNN', KNeighborsClassifier),\n",
        "    ('Linear_SVC', LinearSVC),\n",
        "    ('SGDC', SGDClassifier),\n",
        "    # ('Random_Forest', RandomForestClassifier),\n",
        "]\n",
        "\n",
        "for name, model_class in models:\n",
        "    grid_search_evaluate(name, model_class, eval(name.lower() + '_grid'))  # Use corresponding grid\n",
        "\n",
        "print(\"Grid Search Evaluation Completed!\")\n"
      ],
      "metadata": {
        "id": "br2J6sVKX7YA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cefc9de-3095-401b-bae9-cd06878f19c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB (Grid Search):\n",
            "Best Accuracy: 0.86\n",
            "Test Accuracy: 86.75%\n",
            "Best Parameters: {'alpha': 1}\n",
            "MultinomialNB classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.86      0.88      0.87      7499\n",
            "    Negative       0.87      0.86      0.87      7501\n",
            "\n",
            "    accuracy                           0.87     15000\n",
            "   macro avg       0.87      0.87      0.87     15000\n",
            "weighted avg       0.87      0.87      0.87     15000\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "15 fits failed out of a total of 30.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.82191429        nan 0.8642            nan 0.88997143]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic_Regression (Grid Search):\n",
            "Best Accuracy: 0.89\n",
            "Test Accuracy: 89.43%\n",
            "Best Parameters: {'C': 1, 'penalty': 'l2'}\n",
            "Logistic_Regression classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.91      0.88      0.89      7499\n",
            "    Negative       0.88      0.91      0.90      7501\n",
            "\n",
            "    accuracy                           0.89     15000\n",
            "   macro avg       0.89      0.89      0.89     15000\n",
            "weighted avg       0.89      0.89      0.89     15000\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Linear_SVC (Grid Search):\n",
            "Best Accuracy: 0.89\n",
            "Test Accuracy: 89.59%\n",
            "Best Parameters: {'C': 0.1}\n",
            "Linear_SVC classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.91      0.88      0.89      7499\n",
            "    Negative       0.88      0.91      0.90      7501\n",
            "\n",
            "    accuracy                           0.90     15000\n",
            "   macro avg       0.90      0.90      0.90     15000\n",
            "weighted avg       0.90      0.90      0.90     15000\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGDC (Grid Search):\n",
            "Best Accuracy: 0.89\n",
            "Test Accuracy: 89.55%\n",
            "Best Parameters: {'alpha': 0.0001, 'loss': 'hinge'}\n",
            "SGDC classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.91      0.88      0.89      7499\n",
            "    Negative       0.88      0.91      0.90      7501\n",
            "\n",
            "    accuracy                           0.90     15000\n",
            "   macro avg       0.90      0.90      0.90     15000\n",
            "weighted avg       0.90      0.90      0.90     15000\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Grid Search Evaluation Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the TF-IDF Vectorizer to Googlr Drive for Project Implementation"
      ],
      "metadata": {
        "id": "mcvL-6g5MQXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Assuming \"MinorProjectDatasets\" is in the root of your drive\n",
        "basePath = '/content/drive/MyDrive/MinorProjectDatasets'\n",
        "import pickle\n",
        "\n",
        "# Save the TF-IDF vectorizer\n",
        "with open(f'{basePath}/tfidf.pkl', 'wb') as f:\n",
        "    pickle.dump(tfidf, f)\n"
      ],
      "metadata": {
        "id": "KqnFX1QzAhA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the Models to Google Drive"
      ],
      "metadata": {
        "id": "wOrW0Sy4Mbcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models\n",
        "for name, clf in classifiers.items():\n",
        "    model_path = f'/content/drive/MyDrive/MinorProjectDatasets/{name}.pkl'\n",
        "    with open(model_path, 'wb') as f:\n",
        "        pickle.dump(clf, f)"
      ],
      "metadata": {
        "id": "v_1AK-j3BNhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Model\n",
        "\n",
        "1.   Model Creation,training and testing\n",
        "2.   Model Evaluation\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "86980PxuNn-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/MinorProjectDatasets/IMDB_Dataset_Cleaned.csv')\n",
        "\n",
        "# Drop rows with missing values\n",
        "df1 = df1.dropna(subset=['cleaned_text'])\n",
        "df1 = df1.dropna(subset=['sentiment'])\n",
        "# Split data into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(df1['cleaned_text'], df1['sentiment'], test_size=0.30, random_state=2)\n",
        "\n",
        "# Convert sentiments to 1 and 0\n",
        "y_train = (y_train.replace({'positive': 1, 'negative': 0})).values\n",
        "y_test = (y_test.replace({'positive': 1, 'negative': 0})).values\n",
        "\n",
        "# # Initialize TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(strip_accents=None,\n",
        "                         lowercase=True,\n",
        "                         preprocessor=None,  # applied preprocessor in Data Cleaning\n",
        "                         tokenizer=None,\n",
        "                         use_idf=True,\n",
        "                         norm='l2',\n",
        "                         smooth_idf=True)\n",
        "\n",
        "\n",
        "# Transform text data\n",
        "x_train_tfidf = tfidf.fit_transform(x_train)\n",
        "x_test_tfidf = tfidf.transform(x_test)\n",
        "# Model training and evaluation\n",
        "classifiers = {\n",
        "    # \"Naive_Bayes\": MultinomialNB(),\n",
        "    # \"Logistic_Regression\": LogisticRegression(),\n",
        "    # \"KNN\": KNeighborsClassifier(),\n",
        "    # \"Linear_SVC\": LinearSVC(),\n",
        "    # \"Stochastic_Gradient_Classifier\": SGDClassifier(),\n",
        "    \"Random_Forest\": RandomForestClassifier()\n",
        "}\n",
        "\n",
        "print(\"With Data Pre-Processing:\")\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(x_train_tfidf, y_train)\n",
        "    y_pred = clf.predict(x_test_tfidf)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} accuracy_score = {accuracy * 100:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "# Classification report (ensure consistent target names)\n",
        "    report = classification_report(y_test, y_pred, target_names=['Positive', 'Negative'])\n",
        "    print(f\"{name} classification report:\\n{report}\")"
      ],
      "metadata": {
        "id": "ysC4BM-0LL1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b20630-f176-461f-db19-4f2c5d997289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "With Data Pre-Processing:\n",
            "Random_Forest accuracy_score = 85.77%\n",
            "Random_Forest classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.86      0.86      0.86      7499\n",
            "    Negative       0.86      0.86      0.86      7501\n",
            "\n",
            "    accuracy                           0.86     15000\n",
            "   macro avg       0.86      0.86      0.86     15000\n",
            "weighted avg       0.86      0.86      0.86     15000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing Hyperparameter Tuning on RF Model"
      ],
      "metadata": {
        "id": "_STF3jpK3rZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.base import clone  # Import clone function\n",
        "\n",
        "\n",
        "def grid_search_evaluate(model_name, model_class, param_grid):\n",
        "    \"\"\"\n",
        "    Performs Grid Search for hyperparameter tuning and evaluates the model.\n",
        "\n",
        "    Args:\n",
        "        model_name: Name of the model being evaluated.\n",
        "        model_class: The model class (e.g., MultinomialNB).\n",
        "        param_grid: Dictionary containing hyperparameter names and their values to explore.\n",
        "\n",
        "    Returns:\n",
        "        None (prints results)\n",
        "    \"\"\"\n",
        "    # Perform Grid Search\n",
        "    grid_search = GridSearchCV(model_class(), param_grid, cv=5, scoring='accuracy')\n",
        "    grid_search.fit(x_train_tfidf, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "    best_accuracy = grid_search.best_score_\n",
        "\n",
        "    # Evaluate and print results\n",
        "    y_pred = best_model.predict(x_test_tfidf)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{model_name} (Grid Search):\")\n",
        "    print(f\"Best Accuracy: {best_accuracy:.2f}\")\n",
        "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "    print(f\"{model_name} classification report:\\n{classification_report(y_test, y_pred, target_names=['Positive', 'Negative'])}\")\n",
        "    print(\"-\" * 80)  # Separator for clarity\n",
        "\n",
        "# Define hyperparameter grids (adjust values and parameters as needed)\n",
        "# multinomialnb_grid = {'alpha': [0.01, 0.1, 1]}\n",
        "# logistic_regression_grid = {'C': [0.01, 0.1, 1], 'penalty': ['l1', 'l2']}\n",
        "# knn_grid = {'n_neighbors': range(1, 10), 'algorithm': ['auto', 'ball_tree', 'kd_tree']}\n",
        "# linear_svc_grid = {'C': [0.01, 0.1, 1]}\n",
        "# sgdc_grid = {'alpha': [0.0001, 0.001, 0.01], 'loss': ['hinge', 'log']}\n",
        "random_forest_grid = {'n_estimators': [100, 200, 300], 'max_depth': [5, 10, 15]}\n",
        "\n",
        "# Evaluate\n",
        "models = [\n",
        "    # ('MultinomialNB', MultinomialNB),\n",
        "    # ('Logistic_Regression', LogisticRegression),\n",
        "    #  ('KNN', KNeighborsClassifier),\n",
        "    # ('Linear_SVC', LinearSVC),\n",
        "    # ('SGDC', SGDClassifier),\n",
        "     ('Random_Forest', RandomForestClassifier),\n",
        "]\n",
        "\n",
        "for name, model_class in models:\n",
        "    grid_search_evaluate(name, model_class, eval(name.lower() + '_grid'))  # Use corresponding grid\n",
        "\n",
        "print(\"Grid Search Evaluation Completed!\")\n"
      ],
      "metadata": {
        "id": "B1OAFNI3SrHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5ce4f7-159e-4c57-9346-6d9e11d19a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random_Forest (Grid Search):\n",
            "Best Accuracy: 0.85\n",
            "Test Accuracy: 84.89%\n",
            "Best Parameters: {'max_depth': 15, 'n_estimators': 300}\n",
            "Random_Forest classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.87      0.82      0.84      7499\n",
            "    Negative       0.83      0.88      0.85      7501\n",
            "\n",
            "    accuracy                           0.85     15000\n",
            "   macro avg       0.85      0.85      0.85     15000\n",
            "weighted avg       0.85      0.85      0.85     15000\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Grid Search Evaluation Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving RF Model"
      ],
      "metadata": {
        "id": "f3gV3Zc3OBvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models\n",
        "for name, clf in classifiers.items():\n",
        "    model_path = f'/content/drive/MyDrive/MinorProjectDatasets/{name}.pkl'\n",
        "    with open(model_path, 'wb') as f:\n",
        "        pickle.dump(clf, f)"
      ],
      "metadata": {
        "id": "ep7lqkUw92um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing the KNN Model and evaluating the model\n"
      ],
      "metadata": {
        "id": "D-OkUV8rObq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.linear_model import SGDClassifier\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.svm import LinearSVC\n",
        "# from sklearn import metrics\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from google.colab import drive\n",
        "# import pickle\n",
        "# drive.mount('/content/drive',force_remount=True)\n",
        "# df1 = pd.read_csv('/content/drive/MyDrive/MinorProjectDatasets/IMDB_Dataset_Cleaned.csv')\n",
        "\n",
        "# # Drop rows with missing values\n",
        "# df1 = df1.dropna(subset=['cleaned_text'])\n",
        "# df1 = df1.dropna(subset=['sentiment'])\n",
        "# # Split data into train and test sets\n",
        "# x_train, x_test, y_train, y_test = train_test_split(df1['cleaned_text'], df1['sentiment'], test_size=0.30, random_state=2)\n",
        "\n",
        "# # Convert sentiments to 1 and 0\n",
        "# y_train = (y_train.replace({'positive': 1, 'negative': 0})).values\n",
        "# y_test = (y_test.replace({'positive': 1, 'negative': 0})).values\n",
        "\n",
        "# # Initialize TF-IDF vectorizer\n",
        "# tfidf = TfidfVectorizer(strip_accents=None,\n",
        "#                          lowercase=True,\n",
        "#                          preprocessor=None,  # applied preprocessor in Data Cleaning\n",
        "#                          tokenizer=None,\n",
        "#                          use_idf=True,\n",
        "#                          norm='l2',\n",
        "#                          smooth_idf=True)\n",
        "\n",
        "\n",
        "# # Transform text data\n",
        "# x_train_tfidf = tfidf.fit_transform(x_train)\n",
        "# x_test_tfidf = tfidf.transform(x_test)\n",
        "# # Model training and evaluation\n",
        "# classifiers = {\n",
        "#     # \"Naive_Bayes\": MultinomialNB(),\n",
        "#     # \"Logistic_Regression\": LogisticRegression(),\n",
        "#     \"KNN\": KNeighborsClassifier(),\n",
        "#     # \"Linear_SVC\": LinearSVC(),\n",
        "#     # \"Stochastic_Gradient_Classifier\": SGDClassifier(),\n",
        "#     # \"Random_Forest\": RandomForestClassifier()\n",
        "# }\n",
        "\n",
        "# print(\"With Data Pre-Processing:\")\n",
        "# for name, clf in classifiers.items():\n",
        "#     clf.fit(x_train_tfidf, y_train)\n",
        "#     y_pred = clf.predict(x_test_tfidf)\n",
        "#     accuracy = accuracy_score(y_test, y_pred)\n",
        "#     print(f\"{name} accuracy_score = {accuracy * 100:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "# # for name, model_class in models:\n",
        "# #     grid_search_evaluate(name, model_class, eval(name.lower() + '_grid'))  # Use corresponding grid\n",
        "\n",
        "# # print(\"Grid Search Evaluation Completed!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "2TVcLetnat8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaecb4f7-ed78-412c-d82b-a4c899048da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "With Data Pre-Processing:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the KNN Model"
      ],
      "metadata": {
        "id": "aQ7Pf6dxOrPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save models\n",
        "# for name, clf in classifiers.items():\n",
        "#     model_path = f'/content/drive/MyDrive/MinorProjectDatasets/{name}.pkl'\n",
        "#     with open(model_path, 'wb') as f:\n",
        "#         pickle.dump(clf, f)"
      ],
      "metadata": {
        "id": "l26yv00ushkt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}